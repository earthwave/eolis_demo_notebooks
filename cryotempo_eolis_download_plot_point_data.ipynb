{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"cryotempo_logo.png\" alt=\"logo\" width=\"200\"/> <img src=\"esa_logo.png\" alt=\"esa\" width=\"170\"/> <img src=\"earthwave_logo.png\" alt=\"earthwave\" width=\"150\"/> <img src=\"UoE_logo.png\" alt=\"uoe\" width=\"200\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##<strong>*This is a Jupyter notebook that demonstrates how to download and use Cryotempo-EOLIS data, downloaded from Specklia. Here, we will investigate the coverage and quality of the point product*</strong> \n",
    "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "To run this notebook, you will need to make sure that the folllowing packages are installed in your python environment (all can be installed via pip/conda).\n",
    "\n",
    "    - matplotlib: for plotting\n",
    "    - datetime: for handling timestamps\n",
    "    - numpy\n",
    "    - specklia: for data retrieval\n",
    "\n",
    "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install contextily\n",
    "!pip install specklia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###<strong>1) Download Data\n",
    "\n",
    "Regardless of whether you are using the Google Colab environment, or have downloaded this notebook to your local drive, you will first need to download some data. You can use this notebook to plot any CryoTEMPO-EOLIS point data that you choose. For a quick example, follow the below instructions to download a small example dataset.</strong>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports necessary to run the rest of the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import contextily as ctx\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from specklia import Specklia\n",
    "from shapely import Polygon\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "\n",
    "plt.rcParams.update({'font.size': 16})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>The following cells download point product data for the Jakobshavn glacier from Specklia, Earthwave's geospatial point cloud database.</strong>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will instantiate our Specklia Python client. To run the code, you will need to generate your own Specklia API key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_api_key = input('Please generate your own key using https://specklia.earthwave.co.uk/ApiKeys and paste it here:')\n",
    "specklia_client = Specklia(user_api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define our area of interest and query Specklia for data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wider_jakobshavn_area_polygon = Polygon(([-49.97, 68.92], [-48.24, 68.96], [-48.38, 69.86], [-50.19, 69.81], [-49.97, 68.92]))\n",
    "\n",
    "dataset_name = 'CryoTEMPO-EOLIS Point Product'\n",
    "available_datasets = specklia_client.list_datasets()\n",
    "point_product_dataset = available_datasets[\n",
    "    available_datasets['dataset_name'] == dataset_name].iloc[0]\n",
    "\n",
    "point_product_data, sources = specklia_client.query_dataset(\n",
    "    dataset_id=point_product_dataset['dataset_id'],\n",
    "    epsg4326_polygon=wider_jakobshavn_area_polygon,\n",
    "    min_datetime=datetime(2023,1,1),\n",
    "    max_datetime=datetime(2023,3,1))\n",
    "\n",
    "print(\n",
    "    f'Query complete, {len(point_product_data)} points returned, drawn from {len(sources)} original sources.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's explore the retrieved data. First, we can investigate the metadata of the data sources. In the output of this command, we can see lots of additional information associated with the first source, including projection information, product version and support information. This is the same information that would be included in the header of the source NetCDF file!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the EOLIS datasets, the source information will also include the ESA FTP server path of the corresponding stripfile:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, source in enumerate(sources):\n",
    "    print(f'ESA FTP server path of source #{i+1} is: {source[\"source_information\"][\"science_pds_path\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
    "###<strong>2. Investigate the point product</strong>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>Now that the data has been loaded into the notebook, we can use it to investigate the coverage and quality of the CryoTEMPO-EOLIS point prodcut over the Jakobshavn glacier. Let's create some visuals to quickly understand the scope of the point product and its capabilities.</strong>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we run the cell below, we can see that the variables available for analysis include a time, x and y position, elevation and an associated uncertainty value. For more information about the derivation of these variables, see the CryoTEMPO-EOLIS ATBD, available at https://cryotempo-eolis.org/product-description/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Variables returned by query: ', point_product_data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the source information to determine the geospatial projection of the x and y columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "projections = []\n",
    "for i, source in enumerate(sources):\n",
    "    projection_for_source = source[\"source_information\"][\"geospatial_projection\"]\n",
    "    print(f'X and Y columns in source # {i+1} are in projection: {projection_for_source}')\n",
    "    projections.append(projection_for_source)\n",
    "\n",
    "if len(set(projections)) == 1:\n",
    "    print('All the sources use the same projection! We will need this later on.')\n",
    "    geospatial_projection = projections[0]\n",
    "else:\n",
    "    raise ValueError('You queried an area that covers multiple EOLIS regions - the X and Y columns in data returned by your query are not in the same projection. Please run a different query or reproject before continuing!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we make a simple spatial plot of the point product that we have downloaded. This plot shows all point data available for the Jakobshavn glacier in the timeframe that we specified for the query, and demonstrates the spatial coverage achieved using swath processing. In the Figure on the left, the scatter points are colour-coded by their elevations. On the right, the colour demonstrates the uncertainty associated with each point. For more information on the observing tracks of CryoSat and swath processing, see https://earth.esa.int/eogateway/news/cryosats-swath-processing-technique\n",
    "\n",
    "We plot a background map using contextily, this may take a couple of minutes as the background imagery is downloaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(30,15))\n",
    "query_results_sample = point_product_data.sample(1000)\n",
    "\n",
    "for i, column in enumerate(['elevation', 'uncertainty']):\n",
    "    c = axes[i].scatter(point_product_data['x'], point_product_data['y'], c=point_product_data[column], s=1, cmap='viridis')\n",
    "    plt.colorbar(c, ax=axes[i], label=f'{column.title()} [m]')\n",
    "\n",
    "    axes[i].set_xlabel('x [m]')\n",
    "    axes[i].set_ylabel('y [m]')\n",
    "    plt.ticklabel_format(axis='x', style='sci', scilimits=(0,0))\n",
    "    \n",
    "    ctx.add_basemap(axes[i], source=ctx.providers.GeoportailFrance.orthos, zoom=8, crs=geospatial_projection)\n",
    "\n",
    "    # add thumbnail to corner of plot to show where the data is\n",
    "    thumbnail_ax = inset_axes(axes[i], width=\"20%\", height=3, loc='upper left')\n",
    "\n",
    "    # set extent of greenland for thumbnail axis in EPSG:3413\n",
    "    thumbnail_ax.set_ylim(-3400000, -700000)\n",
    "    thumbnail_ax.set_xlim(-700000, 900000)\n",
    "    thumbnail_ax.tick_params(bottom=False, left=False, labelbottom=False, labelleft=False)\n",
    "    for spine in ['bottom', 'top', 'right', 'left']:\n",
    "        thumbnail_ax.spines[spine].set_color('red')\n",
    "\n",
    "    c = thumbnail_ax.scatter(query_results_sample['x'], query_results_sample['y'], c=query_results_sample[column], s=1, cmap='viridis')\n",
    "\n",
    "    # set lower resolution background map for zoomed out plot of greenland\n",
    "    ctx.add_basemap(thumbnail_ax, source=ctx.providers.Esri.WorldImagery, zoom=5, crs=geospatial_projection, attribution=False)\n",
    "\n",
    "t = plt.suptitle('Coverage of CryoTEMPO-EOLIS point product over the Jakobshavn glacier', fontsize=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong> Next, we can calculate some data quality statistics. </strong>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly we calculate the mean and median uncertainties, as well as the standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_unc = np.nanmean(point_product_data['uncertainty'])\n",
    "med_unc = np.nanmedian(point_product_data['uncertainty'])\n",
    "std_unc = np.std(point_product_data['uncertainty'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We next set up some histogram bins, requiring 40 bins in the uncertainty range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.linspace(np.nanmin(point_product_data['uncertainty']),np.nanmax(point_product_data['uncertainty']),40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we plot a histogram of the uncertainty values for this point product dataset, and display the mean and median values, as well as the standard deviation of uncertainties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,1,figsize=(20,10))\n",
    "\n",
    "a = axs.hist(point_product_data['uncertainty'], bins = bins, facecolor='paleturquoise', edgecolor='k', alpha=0.6)\n",
    "\n",
    "axs.vlines(mean_unc, 0, 2.5e4, color='k', linestyle='dashed', label='Mean Uncertainty = {:0.2f}'.format(mean_unc))\n",
    "axs.vlines(med_unc, 0, 2.5e4, color='b', linestyle='dashed', label='Median Uncertainty = {:0.2f}'.format(med_unc))\n",
    "axs.vlines(mean_unc - std_unc, 0, 2.5e4, color='orange', linestyle='dashed')\n",
    "axs.vlines(mean_unc + std_unc, 0, 2.5e4, color='orange', linestyle='dashed',label='$\\sigma$ = {:0.2f}'.format(std_unc))\n",
    "\n",
    "axs.set_ylim(0, 5e4)\n",
    "axs.set_xlabel('Uncertainty [m]')\n",
    "axs.set_ylabel('Frequency')\n",
    "axs.set_title('Uncertainty distribution for CryoTEMPO-EOLIS point product')\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "online-processing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
